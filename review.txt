First, we would like to thank the reviewers for all feedback and fair
criticism, both from the technical and from the writing/presentation point of
view.

For each comment in the reviews, we modified the text accordingly and also
provide a detailed feedback below.
We also identified three main areas that demanded a major review, since they
appeared in comments from all reviewers with variations:

1. Make the paper scope/contributions/limitations more clear/explicit.

   We rewrote parts of the Abstract, and most of the Introduction and
   Conclusion.

   Follows the reviewer comments related to this area:

    - "abstract is very lightweight", "does not address the novelty", "is
      lacking a full rounded overview of the paper by not including some of the
      findings"
    - "the conclusion does not talk to the protocol’s novelty or innovation,
      nor does it provide context in terms of implications or real world
      applications"
    - "the rest of the introduction, however, delves too much into the
       mechanisms of the system"
    - "the introduction should be restructured to simply state what the
       proposed model is all about, what the main contributions are, why this
       is different from other existing models and why this is novel"
    - "the novelty does not come across strongly currently", "the author needs
      to start the paper strong to really pull the reader in and convince about
      the novelty of the proposed model"
    - "the author should clearly identify the novelty and the motivation of his
      work in the introduction comparing it to existing work"

   In the Abstract, we are now more explicit about our main contribution as "a
   reputation system that moderates content and, at the same time, delivers
   network consensus". We also highlight the use of the human authoring ability
   (proof-of-authoring) instead of plain economic resources (proof-of-work/stake)
   to reinforce our contributions.

   In the Introduction, we added an early discussion about the existing support
   for either multi-user/single-node or single-user/multi-node consensus.
   We discuss why multi-user/multi-node consensus is important and set it as
   our research goal. We then discuss the limitations of Bitcoin proof-of-work
   in the context of content publishing. Finally, we discuss our proposal
   considering the limitations of existing work and highlight the key insight
   of using human work as a scarce resource. We also motivate the dVCS
   application example as a collaborative application that requires explicit
   human interactions. We also removed the excess of details on the mechanisms.

   In the Conclusion, we summarize our main contributions again, and mention
   practical uses of the protocol as a decentralized alternative for public
   forums and collaborative applications.

   We also respond individually to each of these comments below.

2. Improve related work.

   Follows the reviewer comments related to this area:
    - "section 5 only provides a very basic related work section", "needs to be
      further developed to truly show how this system differs from and approves
      upon currently available technologies", "particularly section 5.1 just
      scratches the surface and needs to be extended"
    - "the reference list is overall a bit unbalanced, with not enough recent
      academic citations"
    - Does the manuscript contain sufficient and appropriate references?
      2/3 reviewers chose option "Important references are missing; more
      references are needed"
      1/3 chose option "References are sufficient and appropriate"

  Regarding Section 5 (Publish-Subscribe Protocols), and as also discussed
  further, we de-emphasized the pubsub nature of the protocol, highlighting
  that "pubsub middlewares operate at different network layers, which suggests
  that Freechains could benefit of the latter to manage the interconnections
  between peers".
  We added a discussion about Merkle DAGs as self-certifying conversations and
  highlight the semantic aspect of our approach which enables permissionless
  writes.
  We added a comparison with another dVCS with respect to the reputation
  system.
  We added 5 new recent references:
    - [2020] Byzantine eventual consistency and the fundamental limits of
             peer-to-peer databases
    - [2021] Decentralized collaborative version control
    - [2021] Analysis of the matrix event graph replicated data type
    - [2021] Decentralized collaborative version control
    - [2022] Making CRDTs Byzantine Fault Tolerant
  We now use 10 references, most of which are recent (2009, 2014, 2x2018, 2019,
  2020, 3x2021, 2022).

3. Show more discussion/evidence/evaluation about the protocol.

   We added two new subsections to the paper:
    - 3.3: The Consensus and Synchronization Algorithm
    - 3.4: Experiments

   Follows the reviewer comments related to this area:
    - "this paper lacks analysis or experiments to prove the correctness of the
      design"
    - "does the prototype system have sufficient performance to support real
      Internet forums?"
    - "what is the complexity of the proposed algorithm?"
    - "the discussion part needs to be expanded", "the author must discuss the
      efficiency of the proposed approach to deal with different attacks",
      "mention the advantages and disadvantages of the proposed protocol",
      "the attacks that the algorithm can detect and those that cannot detect"
    - "an experimental or simulation results with comparison to existing works
      is missing in this paper"
    - Is the manuscript technically sound?
      2/3 reviewers chose option "Appears to be - but didn't check completely"
      1/3 chose option "Yes"

   The section on experiments evaluates 4 parameters: (a) metadata overhead,
   (b) consensus runtime, (c) graph forks, and (d) blocked messages.
   We simulate the behavior of two publicly available forums (a chat and a
   newsgroup) as if they were using Freechains.
   For item (a), we conclude that "the metatada overhead is not negligible,
   specially for short chat messages, but decreases as the payload increases".
   For item (b), we discuss that the stable consensus rule "conveniently
   settles an upper bound on the input size of the consensus algorithm", which
   makes it practical regardless of the forum size.
   For item (c), we calculate the level of asynchrony (peers working locally)
   and found a ratio around 15%, which "confirms that the simulation achieves a
   reasonable level of asynchrony".
   For item (d), we evaluate "how much bookkeeping is required to sustain
   active users in the forums" and found a ratio below 5%, which "considering
   that users were not aware of the reputation rules, indicates that their
   natural posting behavior matches the rules constraints".

   The section on the consensus algorithm details the necessary steps to
   validate publications consistently across the network: (a)
   Consensus, (b) Synchronization, (c) Verification, (d) Repeat.
   The focus is on step (a), which is an adaptation of Khan's topological
   sorting algorithm to favor branches with more reputation.

-------------------------------------------------------------------------------

The first version of the paper was submitted more than 1 year ago.
In the meantime, we made a slight modification to hard forks, which are now
based on fixed activity thresholds (7 days or 100 posts), and not any longer on
reputation thresholds (which was confusing).
This change does not affect the paper results and discussions, except the part
mentioning hard forks (mainly Section 3.1).

Next, we go through all the comments and respond individually to each of them.

-------------------------------------------------------------------------------

# Reviewer 1

## Comments:

> 1. Keywords should include blockchain.

OK.

> 2. In the abstract and introduction, it is emphasized many times that the
>    protocol proposed in this paper is a publish-subscribe protocol.
>    However, the following design does not reflect the characteristics of the
>    publish-subscribe system.

Agreed. We removed all mentions of "publish-subscribe" from the abstract and
introduction, leaving them to a brief description of the protocol in Section 2
and to related work, but with less focus.

We added a remark in Section 2:

"Note that Freechains does not synchronize peers automatically. There are no
preconfigured peers, no root servers, no peer discovery. All connections happen
through the `send` and `recv` commands which have to specify the peers
explicitly. In this sense, Freechains is conceptually a pubsub on how users
publish and consume content, but it still requires extra network automation."

We also emphasize the layer mismatch in Related Work:

"In summary, Freechains and pubsub middlewares operate at different network
layers, which suggests that Freechains could benefit of the latter to manage
the interconnections between peers."

> 3. Authors should use pseudo-code or flowcharts to describe the system
     design. The use of commands can be designated as supplemental material.

We opted for one-line commands because they are real and provide a concrete
perception of the protocol.
We believe that using pseudo-code would not simplify the presentation while
adding a distracting extra abstraction.
We added a remark about this choice at the beginning of Section 2: "We use the
actual command-line tool provided by the protocol to guide the discussion
through concrete examples."

> 4. Authors should illustrate the contents in Figure 1, Figure 3, and Figure 6
     by tables.

We renamed them all as tables.

> 5. This paper lacks analysis or experiments to prove the correctness of the
     design. For example, is it possible for attackers to manipulate the block
     order in the ordering algorithm shown in Figure 4.A? Does the prototype
     system have sufficient performance to support real Internet forums?

As described before, we added two new subsections to the paper which details
the algorithm and evaluates its performance.
We simulated 10000 messages from real archives with a chat and a newsgroup, and
achieved sufficient performance.

> 6. The organization of the paper can be improved.

The Introduction and Conclusion were mostly rewritten.
We added a new figure to explain the consensus, and added two more sections at
the core of the paper (Section 3).
We also rewrote parts of the Related Work.

-------------------------------------------------------------------------------

# Reviewer 1

## Comments:

> 1. The abstract is very lightweight, presenting only a very brief description
     of what the paper will be addressing. It does not clearly explain the
     application of Bitcoin, and does not address the novelty.
     The abstract is lacking a full rounded overview of the paper by not
     including some of the findings.

Answered above:

   In the Abstract, we are now more explicit about our main contribution as "a
   reputation system that moderates content and, at the same time, delivers
   network consensus". We also highlight the use of the human authoring ability
   (proof-of-authoring) instead of plain economic resources (proof-of-work/stake)
   to reinforce our contributions.

> 2. Similarly, the conclusion does not talk to the protocol’s novelty or
     innovation, nor does it provide context in terms of implications or real
     world applications.

Answered above:

   In the Conclusion, we summarize our main contributions again, and mention
   practical uses of the protocol as a decentralized alternative for public
   forums and collaborative applications.

> 3. The introduction’s second paragraph provides a good insight into the
     problem that is being addressed. The rest of the introduction, however,
     delves too much into the mechanisms of the system. The introduction should
     be restructured to simply state what the proposed model is all about, what
     the main contributions are, why this is different from other existing
     models and why this is novel. The novelty does not come across strongly
     currently. The author needs to start the paper strong to really pull the
     reader in and convince about the novelty of the proposed model.

Answered above:

   In the Introduction, we added an early discussion about the existing support
   for either multi-user/single-node or single-user/multi-node consensus.
   We discuss why multi-user/multi-node consensus is important and set it as
   our research goal. We then discuss the limitations of Bitcoin proof-of-work
   in the context of content publishing. Finally, we discuss our proposal
   considering the limitations of existing work and highlight the key insight
   of using human work as a scarce resource. We also motivate the dVCS
   application example as a collaborative application that requires explicit
   human interactions. We also removed the excess of details on the mechanisms.

## Some specific comments:

> Page 1: “Content publishing in public Internet forums and social media
>         platforms is increasingly more centralized in a few companies.”
>         Which companies? Adding an example here would make it easier for the
>         reader to connect with the paper.

In the beginning of the Introduction, we now mention how Facebook and Twitter
benefit from network effects and avoid open protocols, which lock their users
in the platform.

> Page 1: ‘DAG’ is not introduced as a full term the first time it is used.

The concept of a Merkle DAG now only appears in Section 2 with a reference and
an explanation in sequence:

"...each topic or chain is a replicated Merkle Directed Acyclic Graph [22]...
The DAG represents the causal relationships between the messages, whose
cryptographic links ensure persistence and self-certification of the whole
chain."

> Page 2: What is labelled as Figure 1 is actually a table. This should be
>         updated. Same with Figure 6.

We renamed them all as tables (also Figure 3).

> - Section 2 provides a functional description of Freechains and some metadata
>   at the end of the section. By moving this metadata to the beginning of the
>   section, and just structuring the beginning so that it is clear what the
>   intention of the section is, readability will be greatly improved.

We are now clear about the intention of the section and refer to the figure
with the resulting metadata:

"The goals of this section are twofold:
    (i)  to depict chain DAGs as the result of basic protocol operations; and
    (ii) to illustrate how permissionless protocols inevitably require some
         form o Sybil resistance to become practical."

> - At the moment, Section 1 mentions that Freechains will be used to integrate
>   the protocol, but Section 2 does not shape this within the bigger context
>   of the paper. It would be good if the introduction of Section 2 just guides
>   the reader a bit in terms of why Freechains and how it contributes to the
>   bigger goal of the paper.

The item (ii) above connects Freechains with the rest of the paper.
We now conclude the section as follows:

"Note that the basic operations of Freechains to (i) create decentralized
identities, (ii) publish content-addressable data, (iii) maintain Merkle DAGs,
and (iv) synchronize peers are not new in the context of peer-to-peer
protocols. However, without extra restrictions, any number of users at any
number or peers might inadvertently or maliciously post any kind of content and
rate posts any number of times, thus threatening the value of the protocol.
As discussed in the Introdution, Sybil resistance through consensus is a key
requirement to combat abuse. In the next section, we propose a consensus
mechanism to support public forums in Freechains."

> - Figure 2(C), it is not clear how the ‘likes’ are stored. The figure
>   indicates two arrows, but how is this recorded and stored in the chain?

We now add a sample JSON to illustrate the internal structure of a block:

"As illustrated in Figure 1.C, a like is a regular block with an extra link to
its target. Every new block points to the previous heads, establishing a causal
logical timeline in the chain. For instance, the JSON that follows represents
the block `2_DDA222..` with the backs and extra like links:"

    {
        "id":    "2_DDA222..",  // block hash id
        "backs": ["1_EF5..","1_A22.."] // back links
        "time":  1650722072223, // source timestamp
        "data":  "E95DBF.."     // hash of the payload
        "like":  "1_EF5DE3.."   // like link (optional)
    }

> - Section 3.1: The solution proposed at the top of page 4 should be extended
>   a bit. It is unclear at the moment how malicious users cooperating in the
>   forum matches the problem posed before this, that is, a dislike negates a
>   user’s post. The problem and solution seem a bit disconnected at the moment
>   - somebody disliking a post does not necessarily means malicious intent.

Agreed. We now state the problem as follows:

"Nonetheless, scarce operations are not yet sufficient because they demand
consensus to establish an order in time across the network. As an example,
consider a malicious author with a single unit of reps posting an arbitrary
number of new messages using multiple peers at the same time. According to the
Expense rule of Table 1, only one of these messages should be accepted.
However, without consensus, it is not possible to globally determine which
message to accept, since each peer would supposedly accept the first message it
sees. Therefore, in order to validate operations consistently, we need the same
message ordering across all peers in the network."

> - Figure 4(a): adding the reputation score in the figure will make this more
>   reader friendly and make the examples in the text more self-explanatory.

We added the scores to the figure and updated the text:

"Let's assume that within the prefix, users a and b have contributed with
better content and have more reputation combined than c has alone (i.e.,
8+5>3)."

> - Section 3.1: “If a branch creates enough reps to reach 50% of its prefix”.
>   50% of what? This sentence needs a bit more context. “If a branch creates
>   enough reps to reach 50% of its prefix, then the algorithm orders this
>   branch first in future merges. In the example, suppose that the common
>   prefix accumulates 50 reps considering users a, b, and c. If branch-1
>   creates at least 25 new reps, then the merge with branch-2 will fail and
>   the chains will never synchronize again.” This seems contradictory. If a
>   branch reaches 50% reps of the prefix, then it will be ordered first. That
>   is, using Figure 4, it will be ordered as common prefix, then branch 1,
>   then branch 2. However, in the narrative quoted above, it states the
>   branches will split totally, that would be ordered as prefix, then branch 1
>   and separately, prefix and then branch 2. This is not the same scenario.

We simplified the merge algorithm and hard forks, which are now based on
accumulated time and not reputation. This paragraph has been completely
rewritten and we also added Figure 3 to help in the description.

"Nevertheless, it is unacceptable that a very old remote branch affects a long
active local chain. For this reason, the consensus algorithm includes an extra
constraint when merging: long-lasting local branches do not merge, creating
hard forks in the network. A hard fork occurs when a local branch crosses a
predetermined and irreversible threshold, i.e., 7 days or 100 posts of
activity. In this case, regardless of the remote branch reputation, the local
branch takes priority and is ordered first. This situation is analogous to a
hard fork in Bitcoin and the branches will never synchronize again. More than
simply numeric disputes, hard forks represent social conflicts in which
reconciling branches is no longer possible. Figure 3 illustrates hard forks by
distinguishing stable consensus, which cannot be reordered, from unstable,
which may still be affected by incoming branches. The activity threshold counts
backwards, from the latest local block in the unstable consensus."

The criteria changed from reps to time, but the underlying goal is the same,
that some merges over time are impossible, creating a hard fork in the network.

> - Section 3.2: More details about the pioneers needed. How many pioneers?
    From the discussion it seems that there would be multiple pioneers, but
    then the last sentence of paragraph 2 refers to ‘single pioneer’. This is
    not well written and causing some confusion.

The number of pioneers is arbitrary and is specified on the command join.
We modified the text as follows:

"The join command in rule 1.a bootstraps a public chain, assigning 30 reps
equally distributed between an arbitrary number of pioneers indicated
through their public keys ... The post command in sequence is signed by the
single pioneer (in this example) and indicates the purpose of the chain for
future users."

> - Figure 6 refers to a discount period. This is not clearly explained in the
>   text. The time aspect is also a bit ambiguous. During a 24 hour period, a
>   poster can only get rewarded with 1 rep, although they can post multiple
>   times during that 24 hour period, as long as they have reps available. Is
>   that one rep reward additional to the initial 30 available reps? If not,
>   how would this encourage discussion? If this is addressed in the paper, it
>   did not come across well and needs a bit further refinement to remove
>   ambiguity.

The chosen constants (30 reps, 24 hours, etc) are arbitrary and were designed
with mailing lists in mind.
We modified Figure 6 to include the following caption:

"The chosen constants (30 reos, 24h, 128kb) are arbitrary and target typical
Internet forums with moderate traffic. A future revision of the protocol could
support them as chain parameters."

Even though the +1 rep reward is only accounted after 24h, the -1 rep discount
may be revoked in a very short period depending on the author reputation, which
allows for free posts in sequence, even if they do not award extra reps.
If limiting rep rewards do not encourage discussion, at least, the rule to
revoke the -1 discount will not discourage it.

> - Section 3.2 alludes to the chicken and egg problem, but this is not
>   expanded on. Please do so to ensure that the reader knows exactly what you
>   are referring to.

We modified the text as follows:

"Note that the pioneers rule 1.a solves the chicken-and-egg problem imposed by
rule 4.a: if new authors start with no reps, but require reps to operate, it is
necessary that some authors have initial reps to boot the chains."

> - Section 4 could do with a bit of context at the beginning to explain how
>   CRDTs fit within the bigger scope of the paper.

We now link the consensus mechanism with CRDTs in the Introduction:

"Hence, as a forth contribution, we show how the consensus mechanism can
empower mostly conflict-free replicated data types (quasi-CRDTs) when they do
encounter conflicting operations."

In Section 4, are now more specific about the correspondence:

"However, CRDTs are not a panacea and often require human intervention to solve
specific conflicts, such as manual merges in version control systems (VCSs).
Our observation is that, since the proposed consensus algorithm already relies
on human interactions, we can use it to resolve conflicts automatically."

> - Section 4.1 document the merge process with patching, but the principle of
>   patching is not sufficiently addressed.

We now explain what a patch is and how it relates to CRDTs:

"A commit first makes a checkout from the repository into temporary file
`p2p.remote`. Then, it compares this version against our local changes, saving
the diffs into file `p2p.patch`. A patch contains the minimal set of changes to
apply back into the repository, and represents a CmRDT operation in our model.
Finally, the commit posts the patch file back into the chain.
...
A `checkout` recreates the latest version of the file in the repository by
applying all patches since the genesis block. Recall that each patch represents
a CmRDT operation to recreate the final state of the data."

> - Section 5 only provides a very basic related work section. This section
>   needs to be further developed to truly show how this system differs from
>   and approves upon currently available technologies. Particularly Section
>   5.1 just scratches the surface and needs to be extended.

Answered above:

  Regarding Section 5 (Publish-Subscribe Protocols), and as also discussed
  further, we de-emphasized the pubsub nature of the protocol, highlighting
  that "pubsub middlewares operate at different network layers, which suggests
  that Freechains could benefit of the latter to manage the interconnections
  between peers".

> There are minor language and spelling issues to address:
> - Page 2: of-fline -> off-line
> - Page 2: “...others peers have to...” others -> other
> - Section 3: “million of messages” -> “millions of messages”
> - Section 3.1: “can take advantage” -> “can take advantage of”
> - Section 3.1: “User c represents here a malicious user trying to cultivate
>   the fake identities x and y in separate of the network to accumulate reps.”
>   Sentence missing some words.
> - Figure 6: tranfer -> transfer

OK.

> - There are some references that are incomplete, specifically [1], [7], [14].
>   Reference [16] is incorrectly capitalised.

OK.

> - The reference list is overall a bit unbalanced, with not enough recent
>   academic citations.

Answered above:

  We added 5 new recent references:
    - [2020] Byzantine eventual consistency and the fundamental limits of
             peer-to-peer databases
    - [2021] Decentralized collaborative version control
    - [2021] Analysis of the matrix event graph replicated data type
    - [2021] Decentralized collaborative version control
    - [2022] Making CRDTs Byzantine Fault Tolerant
  We now use 10 references, most of which are recent (2009, 2014, 2x2018, 2019,
  2020, 3x2021, 2022).

-------------------------------------------------------------------------------

# Reviewer 3

## Comments:

> - The author should clearly identify the novelty and the motivation of his
>   work in the introduction comparing it to existing work.

Answered above:

   In the Introduction, we added an early discussion about the existing support
   for either multi-user/single-node or single-user/multi-node consensus.
   We discuss why multi-user/multi-node consensus is important and set it as
   our research goal. We then discuss the limitations of Bitcoin proof-of-work
   in the context of content publishing. Finally, we discuss our proposal
   considering the limitations of existing work and highlight the key insight
   of using human work as a scarce resource. We also motivate the dVCS
   application example as a collaborative application that requires explicit
   human interactions. We also removed the excess of details on the mechanisms.

> - What is the complexity of the proposed algorithm?

We added Section 3.3 to detail the consensus and synchronization algorithm.
The core algorithm is an adaptation of Khan's topological sorting algorithm to
favor branches with more reputation (O(V+N)).

> - The discussion part needs to be expanded. The author must discuss the
>   efficiency of the proposed approach to deal with different attacks, and
>   mention the advantages and disadvantages of the proposed protocol. The
>   attacks that the algorithm can detect and those that cannot detect.
> - An experimental or simulation results with comparison to existing works is
>   missing in this paper.

Answered above:

   The section on experiments evaluates 4 parameters: (a) metadata overhead,
   (b) consensus runtime, (c) graph forks, and (d) blocked messages.
   We simulate the behavior of two publicly available forums (a chat and a
   newsgroup) as if they were using Freechains.
   For item (a), we conclude that "the metatada overhead is not negligible,
   specially for short chat messages, but decreases as the payload increases".
   For item (b), we discuss that the stable consensus rule "conveniently
   settles an upper bound on the input size of the consensus algorithm", which
   makes it practical regardless of the forum size.
   For item (c), we calculate the level of asynchrony (peers working locally)
   and found a ratio around 15%, which "confirms that the simulation achieves a
   reasonable level of asynchrony".
   For item (d), we evaluate "how much bookkeeping is required to sustain
   active users in the forums" and found a ratio below 5%, which "considering
   that users were not aware of the reputation rules, indicates that their
   natural posting behavior matches the rules constraints".
